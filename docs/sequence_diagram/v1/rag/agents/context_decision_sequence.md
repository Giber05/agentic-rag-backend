# Context Decision Agent - Sequence Diagram

## Overview

This sequence diagram illustrates the complete workflow of the Context Decision Agent, which determines whether additional context retrieval is necessary to answer a user's query effectively.

## Sequence Diagram

```mermaid
sequenceDiagram
    participant Client as Client/Pipeline
    participant CDA as ContextDecisionAgent
    participant CM as ContextMemoryManager
    participant SC as SimilarityCalculator
    participant QC as QueryClassificationEngine
    participant AI as AI Assessment Service
    participant DA as DecisionAggregator
    participant Cache as Cache Service
    participant OpenAI as OpenAI API

    Note over Client, OpenAI: Context Decision Agent Processing Flow

    %% 1. Initial Request
    Client->>+CDA: process(input_data)
    Note right of Client: input_data contains:<br/>- query<br/>- conversation_id<br/>- conversation_history<br/>- user_id<br/>- config

    %% 2. Input Validation & Setup
    CDA->>CDA: validate_input(input_data)
    CDA->>CDA: extract_query_and_context()
    CDA->>CDA: initialize_decision_factors()

    %% 3. Cache Check
    CDA->>+Cache: check_decision_cache(query_hash)
    Cache-->>-CDA: cached_decision (if exists)

    alt Cache Hit
        CDA->>CDA: validate_cache_freshness()
        CDA-->>Client: return cached_result
    else Cache Miss - Continue Processing
        Note over CDA: Proceed with full analysis
    end

    %% 4. Context Memory Retrieval
    CDA->>+CM: retrieve_conversation_context(conversation_id)
    CM->>CM: get_recent_exchanges(memory_size)
    CM->>CM: apply_context_decay_scoring()
    CM-->>-CDA: conversation_context[]

    %% 5. Similarity Calculation
    par Similarity Analysis
        CDA->>+SC: calculate_semantic_similarity(query, context)
        SC->>+OpenAI: generate_embeddings(query)
        OpenAI-->>-SC: query_embedding
        SC->>SC: get_context_embeddings(conversation_context)
        SC->>SC: compute_cosine_similarity(query_embedding, context_embeddings)
        SC->>SC: apply_similarity_threshold(similarity_score)
        SC-->>-CDA: similarity_result
        Note right of SC: similarity_result contains:<br/>- similarity_score<br/>- threshold_met<br/>- most_similar_context<br/>- confidence
    end

    %% 6. Query Classification
    par Query Classification
        CDA->>+QC: classify_query_type(query)
        QC->>QC: detect_self_contained_patterns()
        QC->>QC: detect_followup_references()
        QC->>QC: detect_greeting_commands()
        QC->>QC: classify_domain_category()
        QC-->>-CDA: classification_result
        Note right of QC: classification_result contains:<br/>- query_type<br/>- certainty_score<br/>- detected_patterns<br/>- domain_category
    end

    %% 7. AI Assessment (Conditional)
    alt AI Assessment Enabled
        CDA->>+AI: assess_context_necessity(query, context, classification)
        AI->>AI: prepare_assessment_prompt()
        AI->>+OpenAI: create_chat_completion(assessment_prompt)
        OpenAI-->>-AI: ai_response
        AI->>AI: parse_ai_decision()
        AI->>AI: extract_confidence_score()
        AI->>AI: generate_reasoning()
        AI-->>-CDA: ai_assessment_result
        Note right of AI: ai_assessment_result contains:<br/>- decision (boolean)<br/>- confidence<br/>- reasoning<br/>- factors_considered
    else AI Assessment Disabled
        Note over AI: Skip AI assessment<br/>Use rule-based decision only
    end

    %% 8. Decision Aggregation
    CDA->>+DA: aggregate_decision_factors(similarity, classification, ai_assessment)
    DA->>DA: apply_factor_weights()
    DA->>DA: calculate_weighted_score()
    DA->>DA: apply_decision_thresholds()
    DA->>DA: determine_final_decision()
    DA->>DA: calculate_overall_confidence()
    DA->>DA: generate_decision_reasoning()
    DA-->>-CDA: final_decision_result

    %% 9. Adaptive Threshold Management
    alt Adaptive Thresholds Enabled
        CDA->>CDA: update_threshold_history(decision_result)
        CDA->>CDA: analyze_decision_patterns()
        CDA->>CDA: adjust_thresholds_if_needed()
        Note right of CDA: Threshold adaptation based on:<br/>- Recent decision accuracy<br/>- Pattern analysis<br/>- Performance metrics
    end

    %% 10. Result Preparation
    CDA->>CDA: prepare_agent_result()
    CDA->>CDA: compile_decision_metadata()
    CDA->>CDA: format_response_data()

    %% 11. Cache Storage
    CDA->>+Cache: store_decision_result(query_hash, result)
    Cache->>Cache: set_ttl(cache_ttl)
    Cache-->>-CDA: cache_stored

    %% 12. Context Memory Update
    CDA->>+CM: update_context_memory(query, decision, metadata)
    CM->>CM: add_decision_to_history()
    CM->>CM: maintain_memory_size_limit()
    CM-->>-CDA: memory_updated

    %% 13. Metrics Collection
    CDA->>CDA: collect_performance_metrics()
    CDA->>CDA: update_decision_statistics()
    CDA->>CDA: log_processing_details()

    %% 14. Return Result
    CDA-->>-Client: AgentResult
    Note right of CDA: AgentResult contains:<br/>- context_required (boolean)<br/>- confidence<br/>- reasoning<br/>- similarity_score<br/>- query_type<br/>- ai_assessment<br/>- factors breakdown<br/>- metadata

    %% Error Handling Flow
    Note over CDA, OpenAI: Error Handling Scenarios

    alt OpenAI API Error
        OpenAI-->>SC: API Error
        SC->>SC: apply_fallback_similarity()
        SC-->>CDA: fallback_similarity_result

        OpenAI-->>AI: API Error
        AI->>AI: disable_ai_assessment()
        AI-->>CDA: fallback_to_rules
    end

    alt Processing Timeout
        CDA->>CDA: detect_timeout()
        CDA->>CDA: apply_default_decision()
        CDA-->>Client: timeout_result
        Note right of CDA: Default: require context<br/>for safety
    end

    alt Invalid Input
        CDA->>CDA: validate_input_data()
        CDA->>CDA: return_validation_error()
        CDA-->>Client: validation_error
    end
```

## Decision Flow Details

### 1. Input Processing

- **Validation**: Ensures required fields (query, conversation_id) are present
- **Extraction**: Parses query text and conversation context
- **Initialization**: Sets up decision factors and weights

### 2. Cache Management

- **Cache Key**: Generated from query hash and conversation context
- **TTL**: 30-minute cache for decision results
- **Validation**: Ensures cached decisions are still relevant

### 3. Context Memory Retrieval

- **Recent Exchanges**: Retrieves last N conversation turns
- **Decay Scoring**: Applies time-based relevance scoring
- **Memory Optimization**: Maintains efficient storage

### 4. Similarity Calculation

- **Embedding Generation**: Creates vector representations using OpenAI
- **Cosine Similarity**: Computes similarity between query and context
- **Threshold Application**: Compares against configurable thresholds

### 5. Query Classification

- **Pattern Detection**: Identifies self-contained, follow-up, greeting patterns
- **Domain Classification**: Categorizes query by subject area
- **Certainty Scoring**: Provides confidence in classification

### 6. AI Assessment (Optional)

- **Prompt Engineering**: Creates structured prompts for LLM analysis
- **Decision Extraction**: Parses boolean decision from AI response
- **Reasoning Capture**: Extracts AI's reasoning for decision

### 7. Decision Aggregation

- **Factor Weighting**: Applies configurable weights to each factor
- **Score Calculation**: Computes weighted decision score
- **Threshold Application**: Determines final boolean decision

### 8. Adaptive Learning

- **Pattern Analysis**: Monitors decision accuracy over time
- **Threshold Adjustment**: Dynamically adjusts decision thresholds
- **Performance Optimization**: Improves accuracy through learning

## Key Decision Factors

### Similarity Score Weight (40%)

```python
similarity_contribution = similarity_score * similarity_weight
# High similarity to recent context â†’ likely no additional context needed
```

### AI Assessment Weight (40%)

```python
ai_contribution = ai_confidence * ai_decision_weight
# AI determines context necessity with reasoning
```

### Query Type Weight (20%)

```python
query_type_contribution = type_certainty * query_type_weight
# Self-contained queries typically don't need context
```

## Performance Characteristics

| Stage                | Average Time | Cache Hit Rate | Error Rate |
| -------------------- | ------------ | -------------- | ---------- |
| Input Validation     | 1ms          | N/A            | 0.1%       |
| Cache Check          | 2ms          | 78%            | 0.01%      |
| Context Retrieval    | 10ms         | 88%            | 0.05%      |
| Similarity Calc      | 45ms         | 65%            | 0.2%       |
| Query Classification | 2ms          | 80%            | 0.1%       |
| AI Assessment        | 60ms         | 75%            | 1.5%       |
| Decision Aggregation | 1ms          | N/A            | 0.01%      |
| **Total Average**    | **52ms**     | **76%**        | **0.3%**   |

## Error Handling Strategies

### OpenAI API Failures

- **Similarity Fallback**: Use cached embeddings or rule-based similarity
- **AI Assessment Fallback**: Disable AI assessment, use rule-based decisions
- **Graceful Degradation**: Continue processing with available factors

### Timeout Handling

- **Default Decision**: Require context for safety when uncertain
- **Partial Results**: Use completed factors for decision if possible
- **Logging**: Record timeout events for monitoring

### Invalid Input

- **Validation Errors**: Return structured error responses
- **Sanitization**: Clean and normalize input where possible
- **Fallback Values**: Use defaults for optional parameters

## Integration Points

### Pipeline Integration

```python
# Called by RAG Pipeline Orchestrator
context_decision_input = {
    "query": rewritten_query,  # From Query Rewriting Agent
    "conversation_id": request.conversation_id,
    "conversation_history": request.conversation_history
}

result = await context_decision_agent.process(context_decision_input)

if result.data["context_required"]:
    # Proceed to Source Retrieval Agent
    await source_retrieval_agent.process(retrieval_input)
else:
    # Skip to Answer Generation with conversation context only
    await answer_generation_agent.process(generation_input)
```

### Monitoring Integration

```python
# Metrics collected during processing
metrics = {
    "decision_latency_ms": processing_time,
    "cache_hit": cache_result.hit,
    "similarity_score": similarity_result.score,
    "ai_assessment_used": ai_enabled,
    "final_decision": decision_result.context_required,
    "confidence_score": decision_result.confidence
}
```

This sequence diagram provides a comprehensive view of the Context Decision Agent's workflow, showing how it intelligently determines whether additional context retrieval is necessary for optimal response generation.
